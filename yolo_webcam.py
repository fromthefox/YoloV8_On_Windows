import cv2
import numpy as np
from ultralytics import YOLO
import time
import os

# å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
try:
    import config
    # ä»é…ç½®æ–‡ä»¶åŠ è½½è®¾ç½®
    MODEL_NAME = config.model_name
    DEVICE = config.device
    CAMERA_ID = config.camera_id
    FRAME_WIDTH = config.frame_width
    FRAME_HEIGHT = config.frame_height
    FPS = config.fps
    CONFIDENCE_THRESHOLD = config.confidence_threshold
    MAX_DETECTIONS = config.max_detections
    SHOW_FPS = config.show_fps
    SHOW_COUNT = config.show_count
    FONT_SCALE = config.font_scale
    LINE_THICKNESS = config.line_thickness
    SAVE_FORMAT = config.save_format
    SAVE_QUALITY = config.save_quality
    SKIP_FRAMES = config.skip_frames
    # å¤šçª—å£è®¾ç½®
    WINDOW_CATEGORIES = config.window_categories
    WINDOW_TITLES = config.window_titles
    WINDOW_POSITIONS = config.window_positions
    # ç‹¬å æ˜¾ç¤ºè®¾ç½®
    EXCLUSIVE_DISPLAY = config.exclusive_display
    EXCLUSIVE_PRIORITY = config.exclusive_priority
    BLACK_SCREEN_TEXT = config.black_screen_text
    SHOW_WAITING_MESSAGE = config.show_waiting_message
    print("âœ“ é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
except ImportError:
    # ä½¿ç”¨é»˜è®¤è®¾ç½®
    MODEL_NAME = "yolov8n.pt"
    DEVICE = "cpu"
    CAMERA_ID = 0
    FRAME_WIDTH = 640
    FRAME_HEIGHT = 480
    FPS = 30
    CONFIDENCE_THRESHOLD = 0.5
    MAX_DETECTIONS = 100
    SHOW_FPS = True
    SHOW_COUNT = True
    FONT_SCALE = 1.0
    LINE_THICKNESS = 2
    SAVE_FORMAT = "jpg"
    SAVE_QUALITY = 95
    SKIP_FRAMES = 0
    # é»˜è®¤å¤šçª—å£è®¾ç½®
    WINDOW_CATEGORIES = {
        "window1": ["person", "train"],
        "window2": ["cell phone", "cup", "car"],
        "window3": ["laptop", "keyboard", "tv", "mouse", "remote"]
    }
    WINDOW_TITLES = {
        "window1": "Window 1 - Person & Train",
        "window2": "Window 2 - Phone & Cup & Car", 
        "window3": "Window 3 - Computer & Keyboard"
    }
    WINDOW_POSITIONS = {
        "window1": (50, 50),
        "window2": (700, 50),
        "window3": (350, 400)
    }
    # é»˜è®¤ç‹¬å æ˜¾ç¤ºè®¾ç½®
    EXCLUSIVE_DISPLAY = True
    EXCLUSIVE_PRIORITY = ["window1", "window2", "window3"]
    BLACK_SCREEN_TEXT = "No Detection"
    SHOW_WAITING_MESSAGE = True
    print("âš  é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")


class YoloV8Detector:
    def __init__(self, model_path=MODEL_NAME, device=DEVICE):
        """
        åˆå§‹åŒ–YOLOv8æ£€æµ‹å™¨
        
        Args:
            model_path (str): YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„
            device (str): è®¾å¤‡ç±»å‹ï¼Œ'cpu' æˆ– 'cuda'
        """
        self.model_path = model_path
        self.device = device
        self.confidence_threshold = CONFIDENCE_THRESHOLD
        self.max_detections = MAX_DETECTIONS
        
        # åŠ è½½YOLOv8æ¨¡å‹
        print(f"åŠ è½½YOLOv8æ¨¡å‹: {model_path}")
        self.model = YOLO(model_path)
        
        # è®¾ç½®è®¾å¤‡
        if device == 'cpu':
            print("ä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
        else:
            print(f"ä½¿ç”¨è®¾å¤‡: {device}")
            
        # COCOæ•°æ®é›†ç±»åˆ«åç§°
        self.class_names = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
        
        # é¢œè‰²åˆ—è¡¨ï¼ˆBGRæ ¼å¼ï¼‰
        self.colors = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),
            (0, 255, 255), (128, 0, 128), (255, 165, 0), (255, 20, 147), (0, 128, 128),
            (128, 128, 0), (255, 192, 203), (128, 0, 0), (0, 128, 0), (0, 0, 128),
            (128, 128, 128), (255, 255, 255), (0, 0, 0), (255, 69, 0), (50, 205, 50)
        ]
        
        # ä¸ºéšæœºåˆ†é…åˆ›å»ºæ‰€æœ‰ç±»åˆ«çš„åˆ—è¡¨
        self.all_categories = list(WINDOW_CATEGORIES.values())
        self.all_categories_flat = [item for sublist in self.all_categories for item in sublist]
        
    def categorize_detection(self, class_name):
        """
        æ ¹æ®ç±»åˆ«åç§°ç¡®å®šåº”è¯¥æ˜¾ç¤ºåœ¨å“ªä¸ªçª—å£
        
        Args:
            class_name (str): æ£€æµ‹åˆ°çš„ç±»åˆ«åç§°
            
        Returns:
            str or None: çª—å£åç§° (window1, window2, window3) æˆ– None (ä¸æ˜¾ç¤º)
        """
        # æ£€æŸ¥æ˜¯å¦å±äºç‰¹å®šçª—å£çš„ç±»åˆ«
        for window_name, categories in WINDOW_CATEGORIES.items():
            if class_name in categories:
                return window_name
        
        # å¦‚æœä¸åœ¨æŒ‡å®šç±»åˆ«ä¸­ï¼Œè¿”å›Noneï¼ˆä¸æ˜¾ç¤ºï¼‰
        return None
        
    def detect_multi_window(self, frame):
        """
        å¯¹å•å¸§å›¾åƒè¿›è¡Œç›®æ ‡æ£€æµ‹å¹¶åˆ†ç±»åˆ°ä¸åŒçª—å£
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            
        Returns:
            dict: åŒ…å«ä¸‰ä¸ªçª—å£æ£€æµ‹ç»“æœçš„å­—å…¸
        """
        # è¿›è¡Œæ¨ç†
        results = self.model(frame, device=self.device, verbose=False)
        
        # åˆå§‹åŒ–ä¸‰ä¸ªçª—å£çš„æ£€æµ‹ç»“æœ
        window_results = {
            "window1": {"detections": [], "frame": frame.copy()},
            "window2": {"detections": [], "frame": frame.copy()},
            "window3": {"detections": [], "frame": frame.copy()}
        }
        
        if results and len(results) > 0:
            result = results[0]
            
            # è·å–æ£€æµ‹æ¡†
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()  # è¾¹ç•Œæ¡†åæ ‡
                confidences = result.boxes.conf.cpu().numpy()  # ç½®ä¿¡åº¦
                class_ids = result.boxes.cls.cpu().numpy()  # ç±»åˆ«ID
                
                for i, (box, conf, cls_id) in enumerate(zip(boxes, confidences, class_ids)):
                    if conf > self.confidence_threshold:
                        x1, y1, x2, y2 = box.astype(int)
                        class_name = self.class_names[int(cls_id)]
                        
                        # ç¡®å®šåº”è¯¥æ˜¾ç¤ºåœ¨å“ªä¸ªçª—å£
                        target_window = self.categorize_detection(class_name)
                        
                        # åªå¤„ç†åœ¨æŒ‡å®šç±»åˆ«ä¸­çš„æ£€æµ‹ç»“æœ
                        if target_window is not None:
                            # ä¿å­˜æ£€æµ‹ç»“æœ
                            detection_info = {
                                'class': class_name,
                                'confidence': conf,
                                'bbox': [x1, y1, x2, y2],
                                'color': self.colors[int(cls_id) % len(self.colors)]
                            }
                            
                            window_results[target_window]["detections"].append(detection_info)
                            
                            # åœ¨å¯¹åº”çª—å£çš„å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
                            self.draw_detection(window_results[target_window]["frame"], detection_info)
        
        return window_results
        
    def draw_detection(self, frame, detection_info):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        
        Args:
            frame: å›¾åƒå¸§
            detection_info: æ£€æµ‹ä¿¡æ¯å­—å…¸
        """
        x1, y1, x2, y2 = detection_info['bbox']
        color = detection_info['color']
        class_name = detection_info['class']
        conf = detection_info['confidence']
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, LINE_THICKNESS)
        
        # ç»˜åˆ¶æ ‡ç­¾
        label = f'{class_name}: {conf:.2f}'
        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.5, LINE_THICKNESS)[0]
        cv2.rectangle(frame, (x1, y1 - label_size[1] - 10),
                     (x1 + label_size[0], y1), color, -1)
        cv2.putText(frame, label, (x1, y1 - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.5, (255, 255, 255), LINE_THICKNESS)
        
    def create_black_screen(self, width, height, window_name):
        """
        åˆ›å»ºé»‘å±å›¾åƒ
        
        Args:
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            window_name: çª—å£åç§°
            
        Returns:
            black_screen: é»‘å±å›¾åƒ
        """
        # åˆ›å»ºé»‘è‰²èƒŒæ™¯
        black_screen = np.zeros((height, width, 3), dtype=np.uint8)
        
        if SHOW_WAITING_MESSAGE:
            # æ·»åŠ ç­‰å¾…æ¶ˆæ¯
            window_id = window_name[-1]
            
            # ä¸»è¦æ–‡æœ¬
            main_text = f"Window {window_id}"
            text_size = cv2.getTextSize(main_text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]
            text_x = (width - text_size[0]) // 2
            text_y = height // 2 - 60
            cv2.putText(black_screen, main_text, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (100, 100, 100), 2)
            
            # çŠ¶æ€æ–‡æœ¬
            status_text = BLACK_SCREEN_TEXT
            text_size = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
            text_x = (width - text_size[0]) // 2
            text_y = height // 2 - 20
            cv2.putText(black_screen, status_text, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (80, 80, 80), 2)
            
            # ç­‰å¾…å›¾æ ‡ (ç®€å•çš„åœ†ç‚¹)
            center_x = width // 2
            center_y = height // 2 + 30
            cv2.circle(black_screen, (center_x, center_y), 10, (60, 60, 60), -1)
            
            # æ˜¾ç¤ºå½“å‰æ—¶é—´
            import time
            current_time = time.strftime("%H:%M:%S")
            time_text = f"Time: {current_time}"
            text_size = cv2.getTextSize(time_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
            text_x = (width - text_size[0]) // 2
            text_y = height - 30
            cv2.putText(black_screen, time_text, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (60, 60, 60), 1)
        
        return black_screen
        
    def determine_active_window(self, window_results):
        """
        ç¡®å®šåº”è¯¥æ˜¾ç¤ºå“ªä¸ªçª—å£ï¼ˆç‹¬å æ˜¾ç¤ºæ¨¡å¼ï¼‰
        
        Args:
            window_results: å„çª—å£çš„æ£€æµ‹ç»“æœ
            
        Returns:
            str: æ´»è·ƒçª—å£åç§°ï¼Œå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ™è¿”å›None
        """
        if not EXCLUSIVE_DISPLAY:
            return None  # éç‹¬å æ¨¡å¼ï¼Œæ‰€æœ‰çª—å£éƒ½æ˜¾ç¤º
        
        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å“ªä¸ªçª—å£æœ‰æ£€æµ‹ç»“æœ
        for window_name in EXCLUSIVE_PRIORITY:
            if window_name in window_results and len(window_results[window_name]["detections"]) > 0:
                return window_name
        
        return None  # æ²¡æœ‰ä»»ä½•çª—å£æœ‰æ£€æµ‹ç»“æœ
        
    def detect(self, frame):
        """
        å¯¹å•å¸§å›¾åƒè¿›è¡Œç›®æ ‡æ£€æµ‹
        
        Args:
            frame: è¾“å…¥å›¾åƒå¸§
            
        Returns:
            tuple: (æ£€æµ‹ç»“æœ, å¸¦æ ‡æ³¨çš„å›¾åƒ)
        """
        # è¿›è¡Œæ¨ç†
        results = self.model(frame, device=self.device, verbose=False)
        
        # è·å–æ£€æµ‹ç»“æœ
        detections = []
        annotated_frame = frame.copy()
        
        if results and len(results) > 0:
            result = results[0]
            
            # è·å–æ£€æµ‹æ¡†
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()  # è¾¹ç•Œæ¡†åæ ‡
                confidences = result.boxes.conf.cpu().numpy()  # ç½®ä¿¡åº¦
                class_ids = result.boxes.cls.cpu().numpy()  # ç±»åˆ«ID
                
                for i, (box, conf, cls_id) in enumerate(zip(boxes, confidences, class_ids)):
                    if conf > self.confidence_threshold:  # ä½¿ç”¨é…ç½®çš„ç½®ä¿¡åº¦é˜ˆå€¼
                        x1, y1, x2, y2 = box.astype(int)
                        class_name = self.class_names[int(cls_id)]
                        
                        # ä¿å­˜æ£€æµ‹ç»“æœ
                        detections.append({
                            'class': class_name,
                            'confidence': conf,
                            'bbox': [x1, y1, x2, y2]
                        })
                        
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        color = self.colors[int(cls_id) % len(self.colors)]
                        cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, LINE_THICKNESS)
                        
                        # ç»˜åˆ¶æ ‡ç­¾
                        label = f'{class_name}: {conf:.2f}'
                        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.5, LINE_THICKNESS)[0]
                        cv2.rectangle(annotated_frame, (x1, y1 - label_size[1] - 10),
                                    (x1 + label_size[0], y1), color, -1)
                        cv2.putText(annotated_frame, label, (x1, y1 - 5),
                                  cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.5, (255, 255, 255), LINE_THICKNESS)
        
        return detections, annotated_frame
        
    def run_webcam(self, camera_id=CAMERA_ID):
        """
        è¿è¡Œæ‘„åƒå¤´å®æ—¶æ£€æµ‹ï¼ˆä¸‰çª—å£æ¨¡å¼ï¼‰
        
        Args:
            camera_id (int): æ‘„åƒå¤´IDï¼Œé»˜è®¤ä¸ºé…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
        """
        # æ‰“å¼€æ‘„åƒå¤´
        cap = cv2.VideoCapture(camera_id)
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)
        cap.set(cv2.CAP_PROP_FPS, FPS)
        
        if not cap.isOpened():
            print(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
            return
            
        print("ğŸ¯ ä¸‰çª—å£å®æ—¶æ£€æµ‹æ¨¡å¼å·²å¯åŠ¨!")
        print("=" * 60)
        print("ğŸ“‹ çª—å£åˆ†ç±»è¯´æ˜:")
        print("  çª—å£1: äººç‰©(person)ã€ç«è½¦(train)")
        print("  çª—å£2: æ‰‹æœº(cell phone)ã€æ¯å­(cup)ã€æ±½è½¦(car)")
        print("  çª—å£3: ç”µè„‘(laptop)ã€é”®ç›˜(keyboard)ã€ç”µè§†(tv)ã€é¼ æ ‡(mouse)ã€é¥æ§å™¨(remote)")
        print("  å…¶ä»–ç±»åˆ«: éšæœºåˆ†é…åˆ°ä¸‰ä¸ªçª—å£")
        print("=" * 60)
        if EXCLUSIVE_DISPLAY:
            print("ğŸ”¥ ç‹¬å æ˜¾ç¤ºæ¨¡å¼:")
            print("  - åªæœ‰æ£€æµ‹åˆ°ç›®æ ‡çš„çª—å£æ‰ä¼šæ˜¾ç¤ºå›¾åƒ")
            print("  - å…¶ä»–çª—å£æ˜¾ç¤ºé»‘å±ç­‰å¾…çŠ¶æ€")
            print("  - ä¼˜å…ˆçº§é¡ºåº:", " -> ".join(EXCLUSIVE_PRIORITY))
            print("=" * 60)
        print("ğŸ® æ“ä½œè¯´æ˜:")
        print("  - æŒ‰ 'q' é”®é€€å‡º")
        print("  - æŒ‰ 's' é”®ä¿å­˜æ‰€æœ‰çª—å£çš„å½“å‰å¸§")
        print("  - æŒ‰ 'c' é”®æ¸…é™¤æ§åˆ¶å°")
        print("  - æŒ‰ '1', '2', '3' é”®åˆ‡æ¢çª—å£ç„¦ç‚¹")
        print("  - æŒ‰ 'e' é”®åˆ‡æ¢ç‹¬å æ˜¾ç¤ºæ¨¡å¼")
        print("=" * 60)
        
        # åˆ›å»ºä¸‰ä¸ªçª—å£
        for window_name, title in WINDOW_TITLES.items():
            cv2.namedWindow(title, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(title, FRAME_WIDTH, FRAME_HEIGHT)
            # è®¾ç½®çª—å£ä½ç½®
            if window_name in WINDOW_POSITIONS:
                x, y = WINDOW_POSITIONS[window_name]
                cv2.moveWindow(title, x, y)
        
        # åˆå§‹åŒ–FPSè®¡ç®—å˜é‡
        prev_time = time.time()
        frame_count = 0
        skip_counter = 0
        
        # ç»Ÿè®¡å˜é‡
        total_detections = {"window1": 0, "window2": 0, "window3": 0}
        
        # ç‹¬å æ˜¾ç¤ºæ¨¡å¼çš„åŠ¨æ€å˜é‡
        current_exclusive_mode = EXCLUSIVE_DISPLAY
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´æ•°æ®")
                    break
                
                # è·³å¸§å¤„ç†ï¼ˆæé«˜æ€§èƒ½ï¼‰
                if SKIP_FRAMES > 0:
                    skip_counter += 1
                    if skip_counter <= SKIP_FRAMES:
                        continue
                    skip_counter = 0
                    
                # è¿›è¡Œå¤šçª—å£ç›®æ ‡æ£€æµ‹
                window_results = self.detect_multi_window(frame)
                
                # ç¡®å®šæ´»è·ƒçª—å£ï¼ˆç‹¬å æ˜¾ç¤ºæ¨¡å¼ï¼‰
                active_window = self.determine_active_window(window_results) if current_exclusive_mode else None
                
                # è®¡ç®—FPS
                current_time = time.time()
                frame_count += 1
                if current_time - prev_time >= 1.0:
                    fps = frame_count / (current_time - prev_time)
                    prev_time = current_time
                    frame_count = 0
                else:
                    fps = 0
                
                # åœ¨æ¯ä¸ªçª—å£ä¸Šæ·»åŠ ä¿¡æ¯å¹¶æ˜¾ç¤º
                for window_name, result in window_results.items():
                    # åˆ¤æ–­å½“å‰çª—å£æ˜¯å¦åº”è¯¥æ˜¾ç¤ºå®é™…å›¾åƒ
                    if current_exclusive_mode:
                        if active_window and window_name == active_window:
                            # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                            annotated_frame = result["frame"]
                            detections = result["detections"]
                        else:
                            # æ˜¾ç¤ºé»‘å±
                            annotated_frame = self.create_black_screen(FRAME_WIDTH, FRAME_HEIGHT, window_name)
                            detections = []
                    else:
                        # éç‹¬å æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰çª—å£
                        annotated_frame = result["frame"]
                        detections = result["detections"]
                    
                    # æ·»åŠ çª—å£ä¿¡æ¯
                    info_y = 30
                    
                    # æ˜¾ç¤ºFPS
                    if SHOW_FPS and fps > 0:
                        color = (0, 255, 0) if not current_exclusive_mode or window_name == active_window else (100, 100, 100)
                        cv2.putText(annotated_frame, f'FPS: {fps:.1f}', (10, info_y),
                                  cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.7, color, LINE_THICKNESS)
                        info_y += 30
                    
                    # æ˜¾ç¤ºå½“å‰çª—å£æ£€æµ‹æ•°é‡
                    if SHOW_COUNT:
                        color = (0, 255, 0) if not current_exclusive_mode or window_name == active_window else (100, 100, 100)
                        cv2.putText(annotated_frame, f'Objects: {len(detections)}', (10, info_y),
                                  cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.7, color, LINE_THICKNESS)
                        info_y += 30
                    
                    # æ˜¾ç¤ºçª—å£æ ‡è¯†
                    window_id = window_name[-1]  # è·å–çª—å£ç¼–å·
                    if current_exclusive_mode and window_name == active_window:
                        color = (0, 255, 255)  # æ´»è·ƒçª—å£ç”¨äº®è‰²
                        status = f'Window {window_id} [ACTIVE]'
                    elif current_exclusive_mode:
                        color = (100, 100, 100)  # éæ´»è·ƒçª—å£ç”¨æš—è‰²
                        status = f'Window {window_id} [WAITING]'
                    else:
                        color = (255, 255, 0)  # æ™®é€šæ¨¡å¼ç”¨é»„è‰²
                        status = f'Window {window_id}'
                    
                    cv2.putText(annotated_frame, status, (10, info_y),
                              cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.7, color, LINE_THICKNESS)
                    
                    # æ˜¾ç¤ºç‹¬å æ¨¡å¼çŠ¶æ€
                    mode_text = "EXCLUSIVE" if current_exclusive_mode else "NORMAL"
                    cv2.putText(annotated_frame, f'Mode: {mode_text}', (10, annotated_frame.shape[0] - 40),
                              cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.5, (255, 255, 255), LINE_THICKNESS)
                    
                    # æ˜¾ç¤ºç½®ä¿¡åº¦é˜ˆå€¼
                    cv2.putText(annotated_frame, f'Confidence: {self.confidence_threshold:.2f}', 
                              (10, annotated_frame.shape[0] - 10),
                              cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE * 0.5, (0, 255, 0), LINE_THICKNESS)
                    
                    # æ›´æ–°æ€»æ£€æµ‹æ•°
                    total_detections[window_name] = len(result["detections"])  # ä½¿ç”¨åŸå§‹æ£€æµ‹æ•°
                    
                    # æ˜¾ç¤ºå›¾åƒ
                    cv2.imshow(WINDOW_TITLES[window_name], annotated_frame)
                
                # æŒ‰é”®å¤„ç†
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    # ä¿å­˜æ‰€æœ‰çª—å£çš„å½“å‰å¸§
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    for window_name, result in window_results.items():
                        window_id = window_name[-1]
                        filename = f'detection_window{window_id}_{timestamp}.{SAVE_FORMAT}'
                        # æ ¹æ®æ¨¡å¼ä¿å­˜å¯¹åº”çš„å›¾åƒ
                        if current_exclusive_mode and active_window and window_name == active_window:
                            save_frame = result["frame"]
                        elif current_exclusive_mode:
                            save_frame = self.create_black_screen(FRAME_WIDTH, FRAME_HEIGHT, window_name)
                        else:
                            save_frame = result["frame"]
                            
                        if SAVE_FORMAT.lower() == 'jpg':
                            cv2.imwrite(filename, save_frame, [cv2.IMWRITE_JPEG_QUALITY, SAVE_QUALITY])
                        else:
                            cv2.imwrite(filename, save_frame)
                    print(f"ğŸ“¸ å·²ä¿å­˜æ‰€æœ‰çª—å£å›¾åƒ ({timestamp})")
                elif key == ord('c'):
                    # æ¸…é™¤æ§åˆ¶å°
                    os.system('cls' if os.name == 'nt' else 'clear')
                    print("ğŸ¯ ä¸‰çª—å£å®æ—¶æ£€æµ‹è¿è¡Œä¸­...")
                    if current_exclusive_mode:
                        print(f"ï¿½ ç‹¬å æ¨¡å¼: å½“å‰æ´»è·ƒçª—å£ - {active_window if active_window else 'æ— '}")
                    print(f"ï¿½ğŸ“Š å½“å‰æ£€æµ‹ç»Ÿè®¡: W1={total_detections['window1']}, W2={total_detections['window2']}, W3={total_detections['window3']}")
                elif key == ord('e'):
                    # åˆ‡æ¢ç‹¬å æ˜¾ç¤ºæ¨¡å¼
                    current_exclusive_mode = not current_exclusive_mode
                    mode_name = "ç‹¬å æ¨¡å¼" if current_exclusive_mode else "æ™®é€šæ¨¡å¼"
                    print(f"ğŸ”„ å·²åˆ‡æ¢åˆ°{mode_name}")
                elif key == ord('1'):
                    # åˆ‡æ¢åˆ°çª—å£1
                    cv2.setWindowProperty(WINDOW_TITLES["window1"], cv2.WND_PROP_TOPMOST, 1)
                    print("ğŸ¯ åˆ‡æ¢åˆ°çª—å£1ç„¦ç‚¹")
                elif key == ord('2'):
                    # åˆ‡æ¢åˆ°çª—å£2
                    cv2.setWindowProperty(WINDOW_TITLES["window2"], cv2.WND_PROP_TOPMOST, 1)
                    print("ğŸ¯ åˆ‡æ¢åˆ°çª—å£2ç„¦ç‚¹")
                elif key == ord('3'):
                    # åˆ‡æ¢åˆ°çª—å£3
                    cv2.setWindowProperty(WINDOW_TITLES["window3"], cv2.WND_PROP_TOPMOST, 1)
                    print("ğŸ¯ åˆ‡æ¢åˆ°çª—å£3ç„¦ç‚¹")
                    
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
            
        finally:
            # é‡Šæ”¾èµ„æº
            cap.release()
            cv2.destroyAllWindows()
            print("ğŸ“Š æœ€ç»ˆæ£€æµ‹ç»Ÿè®¡:")
            print(f"  çª—å£1: {total_detections['window1']} ä¸ªå¯¹è±¡")
            print(f"  çª—å£2: {total_detections['window2']} ä¸ªå¯¹è±¡") 
            print(f"  çª—å£3: {total_detections['window3']} ä¸ªå¯¹è±¡")
            print("ğŸ“± æ‰€æœ‰çª—å£å·²å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("YOLOv8 å®æ—¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹
        detector = YoloV8Detector()
        
        # è¿è¡Œæ‘„åƒå¤´æ£€æµ‹
        detector.run_webcam()
        
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥:")
        print("1. æ˜¯å¦æ­£ç¡®å®‰è£…äº†æ‰€éœ€çš„ä¾èµ–åŒ…")
        print("2. æ‘„åƒå¤´æ˜¯å¦æ­£å¸¸å·¥ä½œ")
        print("3. æ˜¯å¦åœ¨æ­£ç¡®çš„condaç¯å¢ƒä¸­è¿è¡Œ")
        input("æŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main()
